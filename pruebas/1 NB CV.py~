# -*- coding: utf-8 -*-,
import csv
import numpy as np
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.naive_bayes import GaussianNB
from nltk.corpus import stopwords
from sklearn import cross_validation

stopwordlist = stopwords.words('english')

data = []
target = []

count = 0
'''
	Toma del archivo train.csv (cambiar el path) todos los textos de las reviews y los agrega a una lista (data)
	y las clasificaciones de cada review: 1,2,3,4,5 ...
	count muestra el progreso en el avance del procesamiento del archivo de train
'''
with open('../../Data/train_prep.csv', 'r') as csvfile1:
	spamreader = csv.reader(csvfile1)
	for rowlist in spamreader:
		if(count % 1000 == 0):
			print(count)
		data.append(rowlist[9])
		target.append(rowlist[6])
		count+=1

##Split Cross validation
data_train, data_test, target_train, target_test = cross_validation.train_test_split(data, target, test_size=0.4, random_state=0)

'''
	CountVectorizer genera una matriz dispersa (x_train_counts) usando scipy de terminos por documento con la cantidad de ocurrencias de los mismos en cada doc.
'''
count_vect = CountVectorizer(lowercase=True, stop_words=stopwordlist, min_df = 3)
x_train_counts = count_vect.fit_transform(data_train)

tfidf_transformer = TfidfTransformer()
X_train_tfidf = tfidf_transformer.fit_transform(x_train_counts)

'''
	Como segui el ejemplo, use un modelo multinomial, pero tiene todo un listado de modelos supervisados: http://scikit-learn.org/stable/supervised_learning.html#supervised-learning
	
	clf es el modelo entrenado
'''
clf1 = MultinomialNB().fit(X_train_tfidf, target_train)
clf2 = MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True).fit(X_train_tfidf, target_train)
clf3 = MultinomialNB(alpha=0.5, class_prior=None, fit_prior=True).fit(X_train_tfidf, target_train)
clf4 = MultinomialNB(alpha=0.3, class_prior=None, fit_prior=True).fit(X_train_tfidf, target_train)
clf5 = MultinomialNB(alpha=0.2, class_prior=None, fit_prior=True).fit(X_train_tfidf, target_train)
clf6 = MultinomialNB(alpha=0, class_prior=None, fit_prior=True).fit(X_train_tfidf, target_train)
clf7 = MultinomialNB(alpha=0, fit_prior=True).fit(X_train_tfidf, target_train)
clf8 = MultinomialNB(alpha=0, fit_prior=False).fit(X_train_tfidf, target_train)


'''
	para poder clasificar un registro, se debe transformar el mismo para que tenga la misma dimension del modelo (x_new_counts)
	dataTest es un listado de en este caso 10 registros que saque del set de train
'''
x_new_counts = count_vect.transform(data_test)
x_new_counts_tfidf = tfidf_transformer.transform(x_new_counts)

'''
	le indico al modelo que me de una predicci√≥n de los registros transformados
'''
#predicted = clf.predict(x_new_counts)

print(clf1.score(x_new_counts, target_test))
print(clf2.score(x_new_counts, target_test))
print(clf3.score(x_new_counts, target_test))
print(clf4.score(x_new_counts, target_test))
print(clf5.score(x_new_counts, target_test))
print(clf6.score(x_new_counts, target_test))
print(clf7.score(x_new_counts, target_test))
print(clf8.score(x_new_counts, target_test))


